{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "nlp.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamsorri/class2022Spring/blob/main/nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltUO0sYwyGfU"
      },
      "source": [
        "### Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 쪼가리로 나누는거\n",
        "- split 함수"
      ],
      "metadata": {
        "id": "n1kIg3XQcra0"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "di6xZ08xsgO7"
      },
      "source": [
        "import nltk"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- nltk: natural language tool kit"
      ],
      "metadata": {
        "id": "fS9ReqFsdmgQ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbHEyyNHntcZ"
      },
      "source": [
        "text = 'Here’s to the crazy ones, the misfits, the rebels, the troublemakers, the round pegs in the square holes. \\\n",
        "The ones who see things differently — they’re not fond of rules. \\\n",
        "You can quote them, disagree with them, glorify or vilify them, \\\n",
        "but the only thing you can’t do is ignore them because they change things. \\\n",
        "They push the human race forward, and while some may see them as the crazy ones, we see genius, \\\n",
        "because the ones who are crazy enough to think that they can change the world, are the ones who do.'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45jV2UYs1GEC",
        "collapsed": true,
        "outputId": "06890b17-6d5c-4b28-8b91-99477c260aa9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "text.split()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Here’s',\n",
              " 'to',\n",
              " 'the',\n",
              " 'crazy',\n",
              " 'ones,',\n",
              " 'the',\n",
              " 'misfits,',\n",
              " 'the',\n",
              " 'rebels,',\n",
              " 'the',\n",
              " 'troublemakers,',\n",
              " 'the',\n",
              " 'round',\n",
              " 'pegs',\n",
              " 'in',\n",
              " 'the',\n",
              " 'square',\n",
              " 'holes.',\n",
              " 'The',\n",
              " 'ones',\n",
              " 'who',\n",
              " 'see',\n",
              " 'things',\n",
              " 'differently',\n",
              " '—',\n",
              " 'they’re',\n",
              " 'not',\n",
              " 'fond',\n",
              " 'of',\n",
              " 'rules.',\n",
              " 'You',\n",
              " 'can',\n",
              " 'quote',\n",
              " 'them,',\n",
              " 'disagree',\n",
              " 'with',\n",
              " 'them,',\n",
              " 'glorify',\n",
              " 'or',\n",
              " 'vilify',\n",
              " 'them,',\n",
              " 'but',\n",
              " 'the',\n",
              " 'only',\n",
              " 'thing',\n",
              " 'you',\n",
              " 'can’t',\n",
              " 'do',\n",
              " 'is',\n",
              " 'ignore',\n",
              " 'them',\n",
              " 'because',\n",
              " 'they',\n",
              " 'change',\n",
              " 'things.',\n",
              " 'They',\n",
              " 'push',\n",
              " 'the',\n",
              " 'human',\n",
              " 'race',\n",
              " 'forward,',\n",
              " 'and',\n",
              " 'while',\n",
              " 'some',\n",
              " 'may',\n",
              " 'see',\n",
              " 'them',\n",
              " 'as',\n",
              " 'the',\n",
              " 'crazy',\n",
              " 'ones,',\n",
              " 'we',\n",
              " 'see',\n",
              " 'genius,',\n",
              " 'because',\n",
              " 'the',\n",
              " 'ones',\n",
              " 'who',\n",
              " 'are',\n",
              " 'crazy',\n",
              " 'enough',\n",
              " 'to',\n",
              " 'think',\n",
              " 'that',\n",
              " 'they',\n",
              " 'can',\n",
              " 'change',\n",
              " 'the',\n",
              " 'world,',\n",
              " 'are',\n",
              " 'the',\n",
              " 'ones',\n",
              " 'who',\n",
              " 'do.']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 가장 싸고 빠르지만 원시적인 tokenize"
      ],
      "metadata": {
        "id": "NUhotOx_fQOm"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFR-cRaahTPy",
        "collapsed": true,
        "outputId": "7d99fce0-2ef8-432e-84d9-0a3fa09146c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "' '.join(text.split())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Here’s to the crazy ones, the misfits, the rebels, the troublemakers, the round pegs in the square holes. The ones who see things differently — they’re not fond of rules. You can quote them, disagree with them, glorify or vilify them, but the only thing you can’t do is ignore them because they change things. They push the human race forward, and while some may see them as the crazy ones, we see genius, because the ones who are crazy enough to think that they can change the world, are the ones who do.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- join: 다시 결합시켜라"
      ],
      "metadata": {
        "id": "TSYBQw5lfT3v"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gq_lPZMHntcb",
        "collapsed": true,
        "outputId": "3d2b81b6-6e56-49fb-e284-36e277a7bd4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt_tab')\n",
        "words = word_tokenize(text)\n",
        "words"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Here',\n",
              " '’',\n",
              " 's',\n",
              " 'to',\n",
              " 'the',\n",
              " 'crazy',\n",
              " 'ones',\n",
              " ',',\n",
              " 'the',\n",
              " 'misfits',\n",
              " ',',\n",
              " 'the',\n",
              " 'rebels',\n",
              " ',',\n",
              " 'the',\n",
              " 'troublemakers',\n",
              " ',',\n",
              " 'the',\n",
              " 'round',\n",
              " 'pegs',\n",
              " 'in',\n",
              " 'the',\n",
              " 'square',\n",
              " 'holes',\n",
              " '.',\n",
              " 'The',\n",
              " 'ones',\n",
              " 'who',\n",
              " 'see',\n",
              " 'things',\n",
              " 'differently',\n",
              " '—',\n",
              " 'they',\n",
              " '’',\n",
              " 're',\n",
              " 'not',\n",
              " 'fond',\n",
              " 'of',\n",
              " 'rules',\n",
              " '.',\n",
              " 'You',\n",
              " 'can',\n",
              " 'quote',\n",
              " 'them',\n",
              " ',',\n",
              " 'disagree',\n",
              " 'with',\n",
              " 'them',\n",
              " ',',\n",
              " 'glorify',\n",
              " 'or',\n",
              " 'vilify',\n",
              " 'them',\n",
              " ',',\n",
              " 'but',\n",
              " 'the',\n",
              " 'only',\n",
              " 'thing',\n",
              " 'you',\n",
              " 'can',\n",
              " '’',\n",
              " 't',\n",
              " 'do',\n",
              " 'is',\n",
              " 'ignore',\n",
              " 'them',\n",
              " 'because',\n",
              " 'they',\n",
              " 'change',\n",
              " 'things',\n",
              " '.',\n",
              " 'They',\n",
              " 'push',\n",
              " 'the',\n",
              " 'human',\n",
              " 'race',\n",
              " 'forward',\n",
              " ',',\n",
              " 'and',\n",
              " 'while',\n",
              " 'some',\n",
              " 'may',\n",
              " 'see',\n",
              " 'them',\n",
              " 'as',\n",
              " 'the',\n",
              " 'crazy',\n",
              " 'ones',\n",
              " ',',\n",
              " 'we',\n",
              " 'see',\n",
              " 'genius',\n",
              " ',',\n",
              " 'because',\n",
              " 'the',\n",
              " 'ones',\n",
              " 'who',\n",
              " 'are',\n",
              " 'crazy',\n",
              " 'enough',\n",
              " 'to',\n",
              " 'think',\n",
              " 'that',\n",
              " 'they',\n",
              " 'can',\n",
              " 'change',\n",
              " 'the',\n",
              " 'world',\n",
              " ',',\n",
              " 'are',\n",
              " 'the',\n",
              " 'ones',\n",
              " 'who',\n",
              " 'do',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 쉼표도 따로 분류. 조금 더 발전된 방식"
      ],
      "metadata": {
        "id": "fPZuNjgzfxwW"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RC1fe7nWF6wN",
        "collapsed": true,
        "outputId": "c3444fc9-536f-4db1-9c4d-2ec06f224937",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "retokenize = RegexpTokenizer(\"[\\w]+\")\n",
        "words = retokenize.tokenize(text)\n",
        "words"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Here',\n",
              " 's',\n",
              " 'to',\n",
              " 'the',\n",
              " 'crazy',\n",
              " 'ones',\n",
              " 'the',\n",
              " 'misfits',\n",
              " 'the',\n",
              " 'rebels',\n",
              " 'the',\n",
              " 'troublemakers',\n",
              " 'the',\n",
              " 'round',\n",
              " 'pegs',\n",
              " 'in',\n",
              " 'the',\n",
              " 'square',\n",
              " 'holes',\n",
              " 'The',\n",
              " 'ones',\n",
              " 'who',\n",
              " 'see',\n",
              " 'things',\n",
              " 'differently',\n",
              " 'they',\n",
              " 're',\n",
              " 'not',\n",
              " 'fond',\n",
              " 'of',\n",
              " 'rules',\n",
              " 'You',\n",
              " 'can',\n",
              " 'quote',\n",
              " 'them',\n",
              " 'disagree',\n",
              " 'with',\n",
              " 'them',\n",
              " 'glorify',\n",
              " 'or',\n",
              " 'vilify',\n",
              " 'them',\n",
              " 'but',\n",
              " 'the',\n",
              " 'only',\n",
              " 'thing',\n",
              " 'you',\n",
              " 'can',\n",
              " 't',\n",
              " 'do',\n",
              " 'is',\n",
              " 'ignore',\n",
              " 'them',\n",
              " 'because',\n",
              " 'they',\n",
              " 'change',\n",
              " 'things',\n",
              " 'They',\n",
              " 'push',\n",
              " 'the',\n",
              " 'human',\n",
              " 'race',\n",
              " 'forward',\n",
              " 'and',\n",
              " 'while',\n",
              " 'some',\n",
              " 'may',\n",
              " 'see',\n",
              " 'them',\n",
              " 'as',\n",
              " 'the',\n",
              " 'crazy',\n",
              " 'ones',\n",
              " 'we',\n",
              " 'see',\n",
              " 'genius',\n",
              " 'because',\n",
              " 'the',\n",
              " 'ones',\n",
              " 'who',\n",
              " 'are',\n",
              " 'crazy',\n",
              " 'enough',\n",
              " 'to',\n",
              " 'think',\n",
              " 'that',\n",
              " 'they',\n",
              " 'can',\n",
              " 'change',\n",
              " 'the',\n",
              " 'world',\n",
              " 'are',\n",
              " 'the',\n",
              " 'ones',\n",
              " 'who',\n",
              " 'do']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xCPLvzOdgh3m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 빨간 글씨: rule / 가장 깔끔한 방식"
      ],
      "metadata": {
        "id": "im5G1RUFf_BJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pc42Plwx56YS"
      },
      "source": [
        "### Normalization  \n",
        "Stemming(가지치기): am → am, the going → the go, having → hav\n",
        "\n",
        "Lemmatization(원형화): am → be, the going → the going, having → have"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 파생/변형되어 있는 것들을 원형으로 바꾸는 작업"
      ],
      "metadata": {
        "id": "jmVWCinBc0uP"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsFfoAr259Fs",
        "collapsed": true,
        "outputId": "a6bb240d-1935-4c01-e42c-c49b1cd4d183",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "[stemmer.stem(w) for w in words]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['here',\n",
              " 's',\n",
              " 'to',\n",
              " 'the',\n",
              " 'crazi',\n",
              " 'one',\n",
              " 'the',\n",
              " 'misfit',\n",
              " 'the',\n",
              " 'rebel',\n",
              " 'the',\n",
              " 'troublemak',\n",
              " 'the',\n",
              " 'round',\n",
              " 'peg',\n",
              " 'in',\n",
              " 'the',\n",
              " 'squar',\n",
              " 'hole',\n",
              " 'the',\n",
              " 'one',\n",
              " 'who',\n",
              " 'see',\n",
              " 'thing',\n",
              " 'differ',\n",
              " 'they',\n",
              " 're',\n",
              " 'not',\n",
              " 'fond',\n",
              " 'of',\n",
              " 'rule',\n",
              " 'you',\n",
              " 'can',\n",
              " 'quot',\n",
              " 'them',\n",
              " 'disagre',\n",
              " 'with',\n",
              " 'them',\n",
              " 'glorifi',\n",
              " 'or',\n",
              " 'vilifi',\n",
              " 'them',\n",
              " 'but',\n",
              " 'the',\n",
              " 'onli',\n",
              " 'thing',\n",
              " 'you',\n",
              " 'can',\n",
              " 't',\n",
              " 'do',\n",
              " 'is',\n",
              " 'ignor',\n",
              " 'them',\n",
              " 'becaus',\n",
              " 'they',\n",
              " 'chang',\n",
              " 'thing',\n",
              " 'they',\n",
              " 'push',\n",
              " 'the',\n",
              " 'human',\n",
              " 'race',\n",
              " 'forward',\n",
              " 'and',\n",
              " 'while',\n",
              " 'some',\n",
              " 'may',\n",
              " 'see',\n",
              " 'them',\n",
              " 'as',\n",
              " 'the',\n",
              " 'crazi',\n",
              " 'one',\n",
              " 'we',\n",
              " 'see',\n",
              " 'geniu',\n",
              " 'becaus',\n",
              " 'the',\n",
              " 'one',\n",
              " 'who',\n",
              " 'are',\n",
              " 'crazi',\n",
              " 'enough',\n",
              " 'to',\n",
              " 'think',\n",
              " 'that',\n",
              " 'they',\n",
              " 'can',\n",
              " 'chang',\n",
              " 'the',\n",
              " 'world',\n",
              " 'are',\n",
              " 'the',\n",
              " 'one',\n",
              " 'who',\n",
              " 'do']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- for: list comprehension (in 옆에 있는 걸 먼저 읽어라)\n",
        "- list: 여러 아이템이 콤마로 들어가 있는 것\n",
        "- 즉, words라는 list에서 for 루프를 돌림. 단어를 w로 가져와서 stemming을 함.\n",
        "- crazi: 잘못됨. 옛날 방식의 방식이라 사장됨."
      ],
      "metadata": {
        "id": "PK4f2xM7g0Cq"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkbgNiPd8BdL",
        "collapsed": true,
        "outputId": "fb3566ff-0c17-42be-953a-b5c787ba8dba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk.stem import LancasterStemmer\n",
        "stemmer = LancasterStemmer()\n",
        "[stemmer.stem(w) for w in words]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['her',\n",
              " 's',\n",
              " 'to',\n",
              " 'the',\n",
              " 'crazy',\n",
              " 'on',\n",
              " 'the',\n",
              " 'misfit',\n",
              " 'the',\n",
              " 'rebel',\n",
              " 'the',\n",
              " 'troublemak',\n",
              " 'the',\n",
              " 'round',\n",
              " 'peg',\n",
              " 'in',\n",
              " 'the',\n",
              " 'squ',\n",
              " 'hol',\n",
              " 'the',\n",
              " 'on',\n",
              " 'who',\n",
              " 'see',\n",
              " 'thing',\n",
              " 'diff',\n",
              " 'they',\n",
              " 're',\n",
              " 'not',\n",
              " 'fond',\n",
              " 'of',\n",
              " 'rul',\n",
              " 'you',\n",
              " 'can',\n",
              " 'quot',\n",
              " 'them',\n",
              " 'disagr',\n",
              " 'with',\n",
              " 'them',\n",
              " 'glor',\n",
              " 'or',\n",
              " 'vil',\n",
              " 'them',\n",
              " 'but',\n",
              " 'the',\n",
              " 'on',\n",
              " 'thing',\n",
              " 'you',\n",
              " 'can',\n",
              " 't',\n",
              " 'do',\n",
              " 'is',\n",
              " 'ign',\n",
              " 'them',\n",
              " 'becaus',\n",
              " 'they',\n",
              " 'chang',\n",
              " 'thing',\n",
              " 'they',\n",
              " 'push',\n",
              " 'the',\n",
              " 'hum',\n",
              " 'rac',\n",
              " 'forward',\n",
              " 'and',\n",
              " 'whil',\n",
              " 'som',\n",
              " 'may',\n",
              " 'see',\n",
              " 'them',\n",
              " 'as',\n",
              " 'the',\n",
              " 'crazy',\n",
              " 'on',\n",
              " 'we',\n",
              " 'see',\n",
              " 'geni',\n",
              " 'becaus',\n",
              " 'the',\n",
              " 'on',\n",
              " 'who',\n",
              " 'ar',\n",
              " 'crazy',\n",
              " 'enough',\n",
              " 'to',\n",
              " 'think',\n",
              " 'that',\n",
              " 'they',\n",
              " 'can',\n",
              " 'chang',\n",
              " 'the',\n",
              " 'world',\n",
              " 'ar',\n",
              " 'the',\n",
              " 'on',\n",
              " 'who',\n",
              " 'do']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIIh5pYd8f74",
        "collapsed": true,
        "outputId": "5b1e4eac-06bc-482e-deff-86932386fcc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "[lemmatizer.lemmatize(w) for w in words]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Here',\n",
              " 's',\n",
              " 'to',\n",
              " 'the',\n",
              " 'crazy',\n",
              " 'one',\n",
              " 'the',\n",
              " 'misfit',\n",
              " 'the',\n",
              " 'rebel',\n",
              " 'the',\n",
              " 'troublemaker',\n",
              " 'the',\n",
              " 'round',\n",
              " 'peg',\n",
              " 'in',\n",
              " 'the',\n",
              " 'square',\n",
              " 'hole',\n",
              " 'The',\n",
              " 'one',\n",
              " 'who',\n",
              " 'see',\n",
              " 'thing',\n",
              " 'differently',\n",
              " 'they',\n",
              " 're',\n",
              " 'not',\n",
              " 'fond',\n",
              " 'of',\n",
              " 'rule',\n",
              " 'You',\n",
              " 'can',\n",
              " 'quote',\n",
              " 'them',\n",
              " 'disagree',\n",
              " 'with',\n",
              " 'them',\n",
              " 'glorify',\n",
              " 'or',\n",
              " 'vilify',\n",
              " 'them',\n",
              " 'but',\n",
              " 'the',\n",
              " 'only',\n",
              " 'thing',\n",
              " 'you',\n",
              " 'can',\n",
              " 't',\n",
              " 'do',\n",
              " 'is',\n",
              " 'ignore',\n",
              " 'them',\n",
              " 'because',\n",
              " 'they',\n",
              " 'change',\n",
              " 'thing',\n",
              " 'They',\n",
              " 'push',\n",
              " 'the',\n",
              " 'human',\n",
              " 'race',\n",
              " 'forward',\n",
              " 'and',\n",
              " 'while',\n",
              " 'some',\n",
              " 'may',\n",
              " 'see',\n",
              " 'them',\n",
              " 'a',\n",
              " 'the',\n",
              " 'crazy',\n",
              " 'one',\n",
              " 'we',\n",
              " 'see',\n",
              " 'genius',\n",
              " 'because',\n",
              " 'the',\n",
              " 'one',\n",
              " 'who',\n",
              " 'are',\n",
              " 'crazy',\n",
              " 'enough',\n",
              " 'to',\n",
              " 'think',\n",
              " 'that',\n",
              " 'they',\n",
              " 'can',\n",
              " 'change',\n",
              " 'the',\n",
              " 'world',\n",
              " 'are',\n",
              " 'the',\n",
              " 'one',\n",
              " 'who',\n",
              " 'do']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- lemmatizer: 단순 chop이 아니라 원형을 잘 찾아주고 있음"
      ],
      "metadata": {
        "id": "-70kZvCyhsuW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPgIzrjm8_1N"
      },
      "source": [
        "### Stopword"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 최고빈도 단어 중 대명사, to, 전치사, 조동사, you 등은 제껴야 함\n",
        "- meaning word만 남기기 위한 작업"
      ],
      "metadata": {
        "id": "kRqb3fPKdadK"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdM2FaN8ntcc"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "print(words)\n",
        "words = [w for w in words if not w in stopwords.words('english')]\n",
        "print(words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmwXTL0UA5aw"
      },
      "source": [
        "### Collocation, Concordance"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- a랑 b 단어가 같이 나온다"
      ],
      "metadata": {
        "id": "Y4pQoTK8dcpq"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fll4ygxNA3OJ"
      },
      "source": [
        "nltk.download('gutenberg')\n",
        "text = nltk.corpus.gutenberg.raw('austen-emma.txt')\n",
        "words = retokenize.tokenize(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqVXlhIrAtmf"
      },
      "source": [
        "nltk.Text(words).collocations()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aq0wiutwA_au"
      },
      "source": [
        "nltk.Text(words).concordance('Emma', 79, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIAIhXvP_BjU"
      },
      "source": [
        "nltk.Text(words).dispersion_plot([\"Emma\", \"Knightley\", \"Frank\", \"Jane\", \"Harriet\", \"Robert\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWYZOFxq_ex2"
      },
      "source": [
        "nltk.Text(words).similar(\"Emma\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZihiVSBK_vy7"
      },
      "source": [
        "nltk.Text(words).common_contexts([\"Emma\", \"she\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8TrCE14vGcT"
      },
      "source": [
        "### Frequency distribution, Frequency plot"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Frequency: 최고빈도~최저빈도 단어"
      ],
      "metadata": {
        "id": "mijROnZZc-Xl"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdY3m6zSBHic"
      },
      "source": [
        "fd = nltk.FreqDist(words).most_common(20)\n",
        "fd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tpZThNV-ftv"
      },
      "source": [
        "nltk.Text(words).plot(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSOSzIovvKvE"
      },
      "source": [
        "### Dictionary"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- nltk에서는 자체적인 사전을 가지고 있음"
      ],
      "metadata": {
        "id": "DDEz0adXdxIJ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIcAOAvqntce"
      },
      "source": [
        "nltk.download('words')\n",
        "nltk.corpus.words.words('en')[-20:-1]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjAy_Ju7ntce"
      },
      "source": [
        "len(nltk.corpus.words.words('en'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrVGVc0X9j7r"
      },
      "source": [
        "### Regular expression"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 모음으로 시작해서 r/s가 나오고 ed로 끝나는 단어\n",
        "- text search를 위한 rule을 쓰는 작업"
      ],
      "metadata": {
        "id": "P4Z5D4vNeK5u"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQKgoQFI_cG-"
      },
      "source": [
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = re.search('w', 'Words, words, words.')\n",
        "print(out)\n",
        "print(out[0])"
      ],
      "metadata": {
        "id": "ypDm1tB7fsRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = re.search('V', 'Words, words, words.')\n",
        "print(out)"
      ],
      "metadata": {
        "id": "_UFxn0pDG6AI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = re.findall('w', 'Words, words, words.')\n",
        "print(out)"
      ],
      "metadata": {
        "id": "m8x2juS2G-VI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = re.findall('V', 'Words, words, words.')\n",
        "print(out)"
      ],
      "metadata": {
        "id": "Q7St_KyzHFpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = re.sub('w', 'V', 'Words, words, words.')\n",
        "print(out)"
      ],
      "metadata": {
        "id": "_0yzHS5zHLV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7U2pS-NL9p38"
      },
      "source": [
        "'''       Basic Regular Expression Meta-Characters, Including Wildcards, Ranges and Closures\n",
        "\n",
        ".\t        Wildcard, matches any character\n",
        "^abc\t    Matches some pattern abc at the start of a string\n",
        "abc$\t    Matches some pattern abc at the end of a string\n",
        "[abc]\t    Matches one of a set of characters\n",
        "[^abc]    Matches anything but a set of characters\n",
        "[A-Z0-9]\tMatches one of a range of characters\n",
        "ed|ing|s\tMatches one of the specified strings (disjunction)\n",
        "*\t        Zero or more of previous item, e.g. a*, [a-z]* (also known as Kleene Closure)\n",
        "+\t        One or more of previous item, e.g. a+, [a-z]+\n",
        "?\t        Zero or one of the previous item (i.e. optional), e.g. a?, [a-z]?\n",
        "{n}\t      Exactly n repeats where n is a non-negative integer\n",
        "{n,}\t    At least n repeats\n",
        "{,n}\t    No more than n repeats\n",
        "{m,n}\t    At least m and no more than n repeats\n",
        "a(b|c)+\t  Parentheses that indicate the scope of the operators\n",
        "(...)     Matches whatever regular expression is inside the parentheses\n",
        "\\d\n",
        "Matches any decimal digit; this is equivalent to the class [0-9].\n",
        "\\D\n",
        "Matches any non-digit character; this is equivalent to the class [^0-9].\n",
        "\\s\n",
        "Matches any whitespace character; this is equivalent to the class [ \\t\\n\\r\\f\\v].\n",
        "\\S\n",
        "Matches any non-whitespace character; this is equivalent to the class [^ \\t\\n\\r\\f\\v].\n",
        "\\w\n",
        "Matches any alphanumeric character; this is equivalent to the class [a-zA-Z0-9_].\n",
        "\\W\n",
        "Matches any non-alphanumeric character; this is equivalent to the class [^a-zA-Z0-9_].\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sp3_Dm9Q_tNQ"
      },
      "source": [
        "engdict = nltk.corpus.words.words('en')\n",
        "\n",
        "result = [w for w in engdict if re.search('ed$', w)]\n",
        "# result = [w for w in engdict if re.search('^..j..t..$', w)]\n",
        "# result = [w for w in engdict if re.search('^[ghi][mno][jlk][def]$', w)]\n",
        "# result = [w for w in engdict if re.search('^[ah]+$', w)][:10]\n",
        "print(result[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1a5mQYj4hwn"
      },
      "source": [
        "nltk.download('treebank')\n",
        "wsj = nltk.corpus.treebank.words()\n",
        "\n",
        "result = [w for w in wsj if re.search('(ed|ing)$', w)]\n",
        "# result = [w for w in wsj if re.search('^[0-9]+\\.[0-9]+$', w)]\n",
        "# result = [w for w in wsj if re.search('^[A-Z]+\\$$', w)]\n",
        "# result = [w for w in wsj if re.search('^[0-9]{4}$', w)]\n",
        "# result = [w for w in wsj if re.search('^[0-9]+-[a-z]{3,5}$', w)]\n",
        "# result = [w for w in wsj if re.search('^[a-z]{5,}-[a-z]{2,3}-[a-z]{,6}$', w)]\n",
        "\n",
        "result = sorted(set(result))\n",
        "print(result[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' lookaround\n",
        "\n",
        "x(?=y) Matches \"x\" only if \"x\" is followed by \"y\"\n",
        "x(?!y) Matches \"x\" only if \"x\" is not followed by \"y\"\n",
        "(?<=y)x Matches \"x\" only if \"x\" is preceded by \"y\"\n",
        "(?<!y)x Matches \"x\" only if \"x\" is not preceded by \"y\""
      ],
      "metadata": {
        "id": "uakyZRspOTzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "re.sub('.afd', 'x', 'ddafadsfsafdsaf')\n",
        "# re.sub('.(?=afd)', 'xx', 'ddafadsfsafdsaf')"
      ],
      "metadata": {
        "id": "RP0GUMkiPxbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# capturing\n",
        "re.findall('\\d{4}-(\\d\\d)-(\\d\\d)', '2028-07-28')"
      ],
      "metadata": {
        "id": "Z0vHmkFmOgZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyIIqwosCRZa"
      },
      "source": [
        "### Extract information (pos tag, named entity)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- pos: 품사 => 품사 분류해주는 작업\n",
        "- named entitiy: 고유명사를 이름/장소 등으로 분류해주는 작업"
      ],
      "metadata": {
        "id": "AY2q05Qwd1v2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VBiObftCVwH"
      },
      "source": [
        "sent = \"I am Jhon from America and would like to go to Starbuck\"\n",
        "words = nltk.word_tokenize(sent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2HuyzFWCe3U"
      },
      "source": [
        "'''\n",
        "POS tag list:\n",
        "\n",
        "CC\tcoordinating conjunction\n",
        "CD\tcardinal digit\n",
        "DT\tdeterminer\n",
        "EX\texistential there (like: \"there is\" ... think of it like \"there exists\")\n",
        "FW\tforeign word\n",
        "IN\tpreposition/subordinating conjunction\n",
        "JJ\tadjective\t'big'\n",
        "JJR\tadjective, comparative\t'bigger'\n",
        "JJS\tadjective, superlative\t'biggest'\n",
        "LS\tlist marker\t1)\n",
        "MD\tmodal\tcould, will\n",
        "NN\tnoun, singular 'desk'\n",
        "NNS\tnoun plural\t'desks'\n",
        "NNP\tproper noun, singular\t'Harrison'\n",
        "NNPS\tproper noun, plural\t'Americans'\n",
        "PDT\tpredeterminer\t'all the kids'\n",
        "POS\tpossessive ending\tparent's\n",
        "PRP\tpersonal pronoun\tI, he, she\n",
        "PRP$\tpossessive pronoun\tmy, his, hers\n",
        "RB\tadverb\tvery, silently,\n",
        "RBR\tadverb, comparative\tbetter\n",
        "RBS\tadverb, superlative\tbest\n",
        "RP\tparticle\tgive up\n",
        "TO\tto\tgo 'to' the store.\n",
        "UH\tinterjection\terrrrrrrrm\n",
        "VB\tverb, base form\ttake\n",
        "VBD\tverb, past tense\ttook\n",
        "VBG\tverb, gerund/present participle\ttaking\n",
        "VBN\tverb, past participle\ttaken\n",
        "VBP\tverb, sing. present, non-3d\ttake\n",
        "VBZ\tverb, 3rd person sing. present\ttakes\n",
        "WDT\twh-determiner\twhich\n",
        "WP\twh-pronoun\twho, what\n",
        "WP$\tpossessive wh-pronoun\twhose\n",
        "WRB\twh-abverb\twhere, when\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwKdu36WCewv"
      },
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "pos = nltk.pos_tag(words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnjGT1HpClE0"
      },
      "source": [
        "nltk.download('maxent_ne_chunker')\n",
        "NE = nltk.ne_chunk(pos)\n",
        "# common Entity types: ORGANIZATION, PERSON, LOCATION, DATE, TIME, MONEY, and GPE (geo-political entity)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jt9DEIZ4lXQF"
      },
      "source": [
        "### Wordcloud"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jypxOnw9hoyZ"
      },
      "source": [
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "text = nltk.corpus.gutenberg.raw('bible-kjv.txt')\n",
        "\n",
        "wc = WordCloud().generate(text)\n",
        "plt.imshow(wc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6xv5ClAl5xk"
      },
      "source": [
        "stopwords = set(STOPWORDS)\n",
        "stopwords.add('unto')\n",
        "wc = WordCloud(stopwords = stopwords).generate(text)\n",
        "plt.imshow(wc)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}